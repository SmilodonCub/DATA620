{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70a12260",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# Elongate: Elon Musk's Twitter Takeover\n",
    "\n",
    "## Using Natural Language Processing and Graph Network Analysis to Examine the Tweeted Conversations about Elon Musk's Acquisition of Twitter.\n",
    "\n",
    "### CUNY MSDS Data620 Final Project\n",
    "\n",
    "Group (lucky) #7: Bonnie Cooper, George Cruz Deschamps, Rob Hodde"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb197ef9",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "## Project Proposal\n",
    "\n",
    "For our Final Project, Group (lucky) #7 would like to perform a social listening analysis on a corpus of tweets that reflect conversations related to Elon Musk. Specifically, we are interested in analyzing content that reflects the timeline of Elon Musk's purchase of Twitter. Our goal is to quantify aspects of the conversations and relate the findings to an established and documented timeline of events. Can we find data driven insights from Twitter activity that is informative of the public's reaction(s) to the news of Twitter's acquision by Musk?  \n",
    "\n",
    "Twitter accepted Elon Musk's acquisition offer on April 25th 2022. However, the weeks leading up to the finalization of the deal were dramatic and tumultuous. After all, Elon had only just purchased a majority sharehold of Twitter on April 4th; this - and the progression of events that culminated in the acquisition - took the tech world by storm. For our project we would like to analyse aspects of the public reaction to these events. Can we find patterns in the volume, sentiment and semantics of Twitter data that inform onthe public's reception the the Twitter takeover."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71959b8",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "## The Data\n",
    "\n",
    "We will collect a corpus of Twitter data to study Elon Musk's Twitter acquisition.  \n",
    "\n",
    "To follow the timeline of events, we will collect tweets from April 1st to May 5th. Tweets will be scraped using the open source Python library [`snscrape`](https://github.com/MartinBeckUT/TwitterScraper) by keyword search using the library's CLI commands.\n",
    "\n",
    "We will briefly discuss collection of a preliminary data set below:  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898eeb78",
   "metadata": {},
   "source": [
    "### Example scraping code\n",
    "\n",
    "```python\n",
    "\n",
    "# import libraries\n",
    "import pandas\n",
    "import os\n",
    "import snscrape\n",
    "\n",
    "# define query variables\n",
    "text_query = \"elon musk\"\n",
    "since_date = \"2022-04-01\"\n",
    "until_date = \"2022-05-05\"\n",
    "\n",
    "# Using OS library to call CLI commands in Python\n",
    "os.system('snscrape --jsonl --since {} twitter-search \"{} until:{}\"> text-query-tweets.json'.format(since_date, text_query, until_date))\n",
    "\n",
    "```\n",
    "\n",
    "Scraping Twitter by running this code in command line resulted in 478321 tweets. The tweet content comes with much metadata about the tweets. The following code will show a glimpse f the raw scraped data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4f4ceb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25670 entries, 0 to 25669\n",
      "Data columns (total 29 columns):\n",
      " #   Column            Non-Null Count  Dtype              \n",
      "---  ------            --------------  -----              \n",
      " 0   _type             25670 non-null  object             \n",
      " 1   url               25670 non-null  object             \n",
      " 2   date              25670 non-null  datetime64[ns, UTC]\n",
      " 3   content           25670 non-null  object             \n",
      " 4   renderedContent   25670 non-null  object             \n",
      " 5   id                25670 non-null  int64              \n",
      " 6   user              25670 non-null  object             \n",
      " 7   replyCount        25670 non-null  int64              \n",
      " 8   retweetCount      25670 non-null  int64              \n",
      " 9   likeCount         25670 non-null  int64              \n",
      " 10  quoteCount        25670 non-null  int64              \n",
      " 11  conversationId    25670 non-null  int64              \n",
      " 12  lang              25670 non-null  object             \n",
      " 13  source            25670 non-null  object             \n",
      " 14  sourceUrl         25670 non-null  object             \n",
      " 15  sourceLabel       25670 non-null  object             \n",
      " 16  outlinks          2815 non-null   object             \n",
      " 17  tcooutlinks       2815 non-null   object             \n",
      " 18  media             2577 non-null   object             \n",
      " 19  retweetedTweet    0 non-null      float64            \n",
      " 20  quotedTweet       1251 non-null   object             \n",
      " 21  inReplyToTweetId  19314 non-null  float64            \n",
      " 22  inReplyToUser     19314 non-null  object             \n",
      " 23  mentionedUsers    23161 non-null  object             \n",
      " 24  coordinates       333 non-null    object             \n",
      " 25  place             333 non-null    object             \n",
      " 26  hashtags          2312 non-null   object             \n",
      " 27  cashtags          201 non-null    object             \n",
      " 28  card              1325 non-null   object             \n",
      "dtypes: datetime64[ns, UTC](1), float64(2), int64(6), object(20)\n",
      "memory usage: 5.7+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "# Reads the gzipped json generated from the CLI command above and creates a pandas dataframe\n",
    "tweets_df = pd.read_json('elongate0000.gz', lines=True, compression='gzip')\n",
    "\n",
    "# Displays information about the fields of metadata\n",
    "tweets_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e909135",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "The raw data returns 29 features. However, not all are necessary for our analysis. Therefore, reduced the size to just the columns of interest:\n",
    "\n",
    "* **date** - time and date of tweet\n",
    "* **id** - unique identifying number for a tweet\n",
    "* **content** - raw tweet content (text, emojis, #s, @s, etc)\n",
    "* **lang** - language classification\n",
    "* **replyCount** - number of replys to this tweet\n",
    "* **retweetCount** - number of retweets to the tweet\n",
    "* **likeCount** - number of likes this tweets recieved\n",
    "* **inReplyToTweetId** - tweet this current tweet was in reply to\n",
    "* **inReplyToUser** - user this current tweet was in reply to\n",
    "* **mentionedUsers** - users mentioned (@) by this current tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cf290e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 478321 entries, 0 to 478320\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   date              478321 non-null  object \n",
      " 1   id                478321 non-null  int64  \n",
      " 2   content           478321 non-null  object \n",
      " 3   lang              478321 non-null  object \n",
      " 4   replyCount        478321 non-null  int64  \n",
      " 5   retweetCount      478321 non-null  int64  \n",
      " 6   likeCount         478321 non-null  int64  \n",
      " 7   inReplyToTweetId  373152 non-null  float64\n",
      " 8   inReplyToUser     373152 non-null  object \n",
      " 9   mentionedUsers    435145 non-null  object \n",
      "dtypes: float64(1), int64(4), object(5)\n",
      "memory usage: 36.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# information about preliminary tweet data\n",
    "df = pd.read_csv( 'elongate_tweets.csv' )\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83284cf",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "## Proposed Methods\n",
    "\n",
    "From the scraped Twitter data we will focus our analysis on three main directions:\n",
    "\n",
    "* Sentiment Analysis: can we observe trends in sentiment and/ or emotion classification across the timeframe of our data collection? Furthermore, can we related shifts in sentiment to events along the timeline?\n",
    "* Topic Cluster Analysis: For the preliminary data set, we collected tweets using a very broad search query term: 'elon musk'. This would return tweets containing the words 'elon' and 'musk'. Can we use topic cluster analysis to isolate tweets more directly related to Elon Musk's Twitter acquisition? Can we learn about other interesting topics being discussed concurrently with the twitter acquisition. How does the volume of tweets compare across topics?\n",
    "* Information Diffusion: Can we apply analyses from previously published approaches (De Domenico 2013) to learn about patterns in the propagation of news about the acquisition?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676bc1ba",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "## References\n",
    "\n",
    "* De Domenico, Manlio, et al. [\"The anatomy of a scientific rumor.\"](https://www.nature.com/articles/srep02980?message-global=remove&WT_ec_id=SREP-20131022) Nature Scientific Reports 3.1 (2013): 1-9.\n",
    "* [Scraping Tweets from Twitter](https://github.com/MartinBeckUT/TwitterScraper)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
